https://github.com/aivarsk/scrapy-proxies or ScrapingHub.com

Scrapy
=======

scrapy3 shell "http://quotes.toscrape.com/"

scrapy3 shell

: fetch("http://quotes.toscrape.com/")
: response.xpath('//h1/a/text()').extract()  #extract_first()
: response.xpath('//*[@class="tag"]') # find all tags with attribute class="tag-item"
: response.xpath('//*[@class="tag-item"/a/text()]') # find all tags with attribute class="tag-item"


cmd

> scrapy3 crawl quotes

alexber\quotes_spider\settings.py
ROBOTSTXT_OBEY


scrapy3 shell

: from scrapy.selector import Selector
: sel = Selector(text=html_doc)
: sel.xpath('html/head/title') #return Selector #extract() text
#select all title nodes
: sel.xpath('//p').extract()
: sel.xpath('//p[1]/text()').extract()
: sel.xpath('//p/text()')[0].extract()
: sel.xpath('//h2/a/@href').extract()


XPath tutorial
https://www.freeformatter.com/xpath-tester.html



scrapy3 shell "http://quotes.toscrape.com/"

: quotes = response.xpath('//*[@class="quote"]')
: quotes[0].xpath('.//a') #dot ensure that search is relative

absoulte_next_page_url = response.urljoin(next_page_url) #from relative to absolute URL
yield scrapy.Request(absoulte_next_page_url)      #new request, callback=pars

scrapy3 crawl quotes -o items.csv
scrapy3 crawl quotes -o items.csv -s DOWNLOAD_DELAY=5

#pip3 install shub==2.8.2 #CLI to depploy to Scrapinghub
shub deploy
